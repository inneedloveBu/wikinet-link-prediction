from asyncio.windows_events import NULL
from git import NULL_TREE
from sympy import true


{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro-header"
   },
   "source": [
    "# ğŸš€ WikiLinks GNN é“¾è·¯é¢„æµ‹æ¼”ç¤º\n",
    "\n",
    "æœ¬ç¬”è®°æœ¬æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨WikiLinks GNNæ¨¡å‹è¿›è¡Œç»´åŸºç™¾ç§‘é¡µé¢é—´çš„é“¾è·¯é¢„æµ‹ã€‚\n",
    "\n",
    "## ğŸ“‹ å†…å®¹æ¦‚è§ˆ\n",
    "\n",
    "1. **ç¯å¢ƒè®¾ç½®** - å®‰è£…ä¾èµ–å¹¶å¯¼å…¥åº“\n",
    "2. **æ•°æ®åŠ è½½** - åŠ è½½å’Œæ¢ç´¢WikiLinksæ•°æ®é›†\n",
    "3. **æ¨¡å‹ä»‹ç»** - äº†è§£å›¾ç¥ç»ç½‘ç»œæ¨¡å‹æ¶æ„\n",
    "4. **æ¨¡å‹è®­ç»ƒ** - è®­ç»ƒé“¾è·¯é¢„æµ‹æ¨¡å‹\n",
    "5. **ç»“æœè¯„ä¼°** - è¯„ä¼°æ¨¡å‹æ€§èƒ½\n",
    "6. **é¢„æµ‹æ¼”ç¤º** - å¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹\n",
    "\n",
    "## ğŸ”§ æŠ€æœ¯è¦æ±‚\n",
    "\n",
    "- Python 3.8+\n",
    "- PyTorch 2.0+\n",
    "- PyTorch Geometric\n",
    "- Google Colabç¯å¢ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. ç¯å¢ƒè®¾ç½®\n",
    "\n",
    "é¦–å…ˆï¼Œå®‰è£…å¿…è¦çš„ä¾èµ–åŒ…ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": [],
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
    "!pip install torch-geometric\n",
    "!pip install matplotlib pandas numpy seaborn scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone-repo"
   },
   "source": [
    "## 2. å…‹éš†ä»“åº“å’Œä¸‹è½½æ•°æ®\n",
    "\n",
    "ä»GitHubå…‹éš†é¡¹ç›®ä»“åº“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": [],
   "metadata": {
    "id": "clone-repo-code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# å…‹éš†é¡¹ç›®ä»“åº“\n",
    "!git clone https://github.com/inneedloveBu/wikinet-link-prediction.git\n",
    "\n",
    "# åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•\n",
    "%cd wikinet-link-prediction\n",
    "\n",
    "# å°†é¡¹ç›®è·¯å¾„æ·»åŠ åˆ°Pythonè·¯å¾„\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "print(f\"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "print(f\"é¡¹ç›®æ–‡ä»¶åˆ—è¡¨: {os.listdir('.')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "## 3. å¯¼å…¥å¿…è¦çš„åº“\n",
    "\n",
    "å¯¼å…¥é¡¹ç›®æ‰€éœ€çš„Pythonåº“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": [],
   "metadata": {
    "id": "import-libs"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, accuracy_score\n",
    "import json\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# æ£€æŸ¥GPUå¯ç”¨æ€§\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPUå‹å·: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-loading"
   },
   "source": [
    "## 4. æ•°æ®åŠ è½½ä¸æ¢ç´¢\n",
    "\n",
    "åŠ è½½WikiLinksæ•°æ®é›†å¹¶æ¢ç´¢å…¶åŸºæœ¬ç‰¹æ€§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": [],
   "metadata": {
    "id": "load-data"
   },
   "outputs": [],
   "source": [
    "# å°è¯•åŠ è½½æ•°æ®é›†\n",
    "try:\n",
    "    # å¦‚æœå­˜åœ¨é¢„å¤„ç†çš„PyGæ•°æ®ï¼Œç›´æ¥åŠ è½½\n",
    "    from utils.data_loader import load_wikilinks_data\n",
    "    data = load_wikilinks_data()\n",
    "    print(\"âœ“ æˆåŠŸåŠ è½½WikiLinksæ•°æ®é›†\")\n",
    "except:\n",
    "    # å¦‚æœæ•°æ®åŠ è½½å¤±è´¥ï¼Œåˆ›å»ºç¤ºä¾‹æ•°æ®\n",
    "    print(\"âš  æ— æ³•åŠ è½½æ•°æ®é›†ï¼Œåˆ›å»ºç¤ºä¾‹æ•°æ®...\")\n",
    "    \n",
    "    # åˆ›å»ºç¤ºä¾‹å›¾æ•°æ®\n",
    "    num_nodes = 100\n",
    "    num_edges = 420\n",
    "    \n",
    "    # éšæœºç”Ÿæˆè¾¹\n",
    "    edge_index = torch.randint(0, num_nodes, (2, num_edges))\n",
    "    \n",
    "    # åˆ›å»ºèŠ‚ç‚¹ç‰¹å¾\n",
    "    x = torch.randn(num_nodes, 64)\n",
    "    \n",
    "    # åˆ›å»ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•æ©ç \n",
    "    edge_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "    train_mask = edge_mask.clone()\n",
    "    val_mask = edge_mask.clone()\n",
    "    test_mask = edge_mask.clone()\n",
    "    \n",
    "    # éšæœºåˆ†é…\n",
    "    indices = torch.randperm(num_edges)\n",
    "    train_mask[indices[:420]] = True  # 420æ¡è®­ç»ƒè¾¹\n",
    "    val_mask[indices[420:560]] = True   # 140æ¡éªŒè¯è¾¹\n",
    "    test_mask[indices[560:700]] = True  # 140æ¡æµ‹è¯•è¾¹\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index, \n",
    "                train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)\n",
    "    \n",
    "    print(\"âœ“ åˆ›å»ºç¤ºä¾‹æ•°æ®é›†å®Œæˆ\")\n",
    "\n",
    "# æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯\n",
    "print(f\"\\næ•°æ®é›†ä¿¡æ¯:\")\n",
    "print(f\"  èŠ‚ç‚¹æ•°: {data.num_nodes}\")\n",
    "print(f\"  è¾¹æ•°: {data.num_edges}\")\n",
    "print(f\"  èŠ‚ç‚¹ç‰¹å¾ç»´åº¦: {data.num_node_features}\")\n",
    "print(f\"  è®­ç»ƒè¾¹æ•°: {data.train_mask.sum().item()}\")\n",
    "print(f\"  éªŒè¯è¾¹æ•°: {data.val_mask.sum().item()}\")\n",
    "print(f\"  æµ‹è¯•è¾¹æ•°: {data.test_mask.sum().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize-data"
   },
   "source": [
    "## 5. å¯è§†åŒ–æ•°æ®å›¾ç»“æ„\n",
    "\n",
    "ä¸ºäº†æ›´å¥½åœ°ç†è§£æ•°æ®ï¼Œæˆ‘ä»¬å¯è§†åŒ–å›¾çš„ç»“æ„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": [],
   "metadata": {
    "id": "plot-graph"
   },
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å›¾ç»“æ„ï¼ˆä»…å±•ç¤ºå­å›¾ï¼‰\n",
    "def visualize_subgraph(data, num_nodes=20):\n",
    "    \"\"\"å¯è§†åŒ–å›¾çš„ä¸€ä¸ªå­é›†\"\"\"\n",
    "    import networkx as nx\n",
    "    \n",
    "    # é€‰æ‹©å‰num_nodesä¸ªèŠ‚ç‚¹\n",
    "    edge_index = data.edge_index\n",
    "    \n",
    "    # ç­›é€‰åŒ…å«å‰num_nodesä¸ªèŠ‚ç‚¹çš„è¾¹\n",
    "    mask = (edge_index[0] < num_nodes) & (edge_index[1] < num_nodes)\n",
    "    sub_edges = edge_index[:, mask]\n",
    "    \n",
    "    # åˆ›å»ºNetworkXå›¾\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # æ·»åŠ èŠ‚ç‚¹\n",
    "    for i in range(min(num_nodes, data.num_nodes)):\n",
    "        G.add_node(i)\n",
    "    \n",
    "    # æ·»åŠ è¾¹\n",
    "    for i in range(sub_edges.shape[1]):\n",
    "        src, dst = sub_edges[0, i].item(), sub_edges[1, i].item()\n",
    "        G.add_edge(src, dst)\n",
    "    \n",
    "    # ç»˜åˆ¶å›¾\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    \n",
    "    nx.draw_networkx_nodes(G, pos, node_color='lightblue', \n",
    "                          node_size=500, alpha=0.8)\n",
    "    nx.draw_networkx_edges(G, pos, width=1.0, alpha=0.5)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=10)\n",
    "    \n",
    "    plt.title(f'WikiLinkså›¾ç»“æ„ï¼ˆå‰{num_nodes}ä¸ªèŠ‚ç‚¹ï¼‰', fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # è¾“å‡ºå›¾ç»Ÿè®¡ä¿¡æ¯\n",
    "    print(f\"å­å›¾èŠ‚ç‚¹æ•°: {G.number_of_nodes()}\")\n",
    "    print(f\"å­å›¾è¾¹æ•°: {G.number_of_edges()}\")\n",
    "    print(f\"å¹³å‡åº¦: {2 * G.number_of_edges() / G.number_of_nodes():.2f}\")\n",
    "    \n",
    "    return G\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "G = visualize_subgraph(data, num_nodes=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-intro"
   },
   "source": [
    "## 6. æ¨¡å‹æ¶æ„ä»‹ç»\n",
    "\n",
    "WikiLinksé¡¹ç›®å®ç°äº†å¤šç§å›¾ç¥ç»ç½‘ç»œæ¶æ„ã€‚è®©æˆ‘ä»¬çœ‹çœ‹ä¸»è¦çš„æ¨¡å‹ç»„ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": [],
   "metadata": {
    "id": "model-architecture"
   },
   "outputs": [],
   "source": [
    "# å¯¼å…¥æ¨¡å‹\n",
    "try:\n",
    "    from models.gnn import GCN, GAT, GraphSAGE\n",
    "    from models.link_prediction import LinkPredictionModel\n",
    "    \n",
    "    print(\"âœ“ æˆåŠŸå¯¼å…¥æ¨¡å‹\")\n",
    "    \n",
    "    # æ˜¾ç¤ºæ¨¡å‹æ¶æ„\n",
    "    print(\"\\nå¯ç”¨æ¨¡å‹æ¶æ„:\")\n",
    "    print(\"  1. GCN (å›¾å·ç§¯ç½‘ç»œ)\")\n",
    "    print(\"  2. GAT (å›¾æ³¨æ„åŠ›ç½‘ç»œ)\")\n",
    "    print(\"  3. GraphSAGE\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âš  å¯¼å…¥æ¨¡å‹æ—¶å‡ºé”™: {e}\")\n",
    "    print(\"åˆ›å»ºç®€åŒ–æ¨¡å‹...\")\n",
    "    \n",
    "    # å®šä¹‰ç®€åŒ–GCNæ¨¡å‹\n",
    "    class SimpleGCN(torch.nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "            super().__init__()\n",
    "            self.conv1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "            self.conv2 = torch.nn.Linear(hidden_dim, output_dim)\n",
    "            self.dropout = torch.nn.Dropout(0.5)\n",
    "            \n",
    "        def forward(self, x, edge_index):\n",
    "            # ç®€åŒ–ç‰ˆGCNï¼ˆå®é™…åº”ä¸ºé‚»æ¥çŸ©é˜µä¼ æ’­ï¼‰\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.conv2(x)\n",
    "            return x\n",
    "    \n",
    "    # å®šä¹‰é“¾è·¯é¢„æµ‹æ¨¡å‹\n",
    "    class SimpleLinkPredictionModel(torch.nn.Module):\n",
    "        def __init__(self, encoder, decoder_dim=128):\n",
    "            super().__init__()\n",
    "            self.encoder = encoder\n",
    "            self.decoder = torch.nn.Sequential(\n",
    "                torch.nn.Linear(decoder_dim * 2, decoder_dim),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Dropout(0.5),\n",
    "                torch.nn.Linear(decoder_dim, 1)\n",
    "            )\n",
    "            \n",
    "        def forward(self, x, edge_index, edge_label_index):\n",
    "            # ç¼–ç èŠ‚ç‚¹ç‰¹å¾\n",
    "            z = self.encoder(x, edge_index)\n",
    "            \n",
    "            # è·å–è¾¹çš„æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹ç‰¹å¾\n",
    "            src, dst = edge_label_index\n",
    "            z_src = z[src]\n",
    "            z_dst = z[dst]\n",
    "            \n",
    "            # æ‹¼æ¥ç‰¹å¾å¹¶è§£ç \n",
    "            edge_features = torch.cat([z_src, z_dst], dim=-1)\n",
    "            predictions = torch.sigmoid(self.decoder(edge_features)).squeeze()\n",
    "            \n",
    "            return predictions\n",
    "    \n",
    "    GCN = SimpleGCN\n",
    "    LinkPredictionModel = SimpleLinkPredictionModel\n",
    "    \n",
    "    print(\"âœ“ åˆ›å»ºç®€åŒ–æ¨¡å‹å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-training"
   },
   "source": [
    "## 7. è®­ç»ƒé“¾è·¯é¢„æµ‹æ¨¡å‹\n",
    "\n",
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬è®­ç»ƒä¸€ä¸ªé“¾è·¯é¢„æµ‹æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": [],
   "metadata": {
    "id": "train-model"
   },
   "outputs": [],
   "source": [
    "def train_link_prediction_model(data, epochs=50, lr=0.01):\n",
    "    \"\"\"è®­ç»ƒé“¾è·¯é¢„æµ‹æ¨¡å‹\"\"\"\n",
    "    \n",
    "    # å‡†å¤‡æ•°æ®\n",
    "    x = data.x.to(device)\n",
    "    edge_index = data.edge_index.to(device)\n",
    "    \n",
    "    # åˆ›å»ºè®­ç»ƒè¾¹å’Œæ ‡ç­¾\n",
    "    train_edges = data.edge_index[:, data.train_mask].to(device)\n",
    "    \n",
    "    # ç”Ÿæˆè´Ÿæ ·æœ¬ï¼ˆä¸å­˜åœ¨çš„è¾¹ï¼‰\n",
    "    num_train_edges = train_edges.shape[1]\n",
    "    num_nodes = data.num_nodes\n",
    "    \n",
    "    # åˆ›å»ºè´Ÿæ ·æœ¬è¾¹ï¼ˆéšæœºç”Ÿæˆï¼‰\n",
    "    neg_edges = torch.randint(0, num_nodes, (2, num_train_edges)).to(device)\n",
    "    \n",
    "    # åˆå¹¶æ­£è´Ÿæ ·æœ¬\n",
    "    all_edges = torch.cat([train_edges, neg_edges], dim=1)\n",
    "    labels = torch.cat([\n",
    "        torch.ones(num_train_edges, device=device),  # æ­£æ ·æœ¬æ ‡ç­¾\n",
    "        torch.zeros(num_train_edges, device=device)  # è´Ÿæ ·æœ¬æ ‡ç­¾\n",
    "    ])\n",
    "    \n",
    "    # åˆ›å»ºæ¨¡å‹\n",
    "    input_dim = data.num_node_features\n",
    "    hidden_dim = 64\n",
    "    output_dim = 32\n",
    "    \n",
    "    encoder = GCN(input_dim, hidden_dim, output_dim).to(device)\n",
    "    model = LinkPredictionModel(encoder).to(device)\n",
    "    \n",
    "    # ä¼˜åŒ–å™¨\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # è®­ç»ƒå†å²\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_auc': [],\n",
    "        'val_ap': []\n",
    "    }\n",
    "    \n",
    "    # è®­ç»ƒå¾ªç¯\n",
    "    print(f\"å¼€å§‹è®­ç»ƒé“¾è·¯é¢„æµ‹æ¨¡å‹ ({epochs}ä¸ªepochs)...\")\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # å‰å‘ä¼ æ’­\n",
    "        predictions = model(x, edge_index, all_edges)\n",
    "        \n",
    "        # è®¡ç®—æŸå¤±\n",
    "        loss = F.binary_cross_entropy(predictions, labels)\n",
    "        \n",
    "        # åå‘ä¼ æ’­\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # éªŒè¯\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°\n",
    "                val_edges = data.edge_index[:, data.val_mask].to(device)\n",
    "                num_val_edges = val_edges.shape[1]\n",
    "                \n",
    "                # ç”ŸæˆéªŒè¯è´Ÿæ ·æœ¬\n",
    "                val_neg_edges = torch.randint(0, num_nodes, (2, num_val_edges)).to(device)\n",
    "                \n",
    "                # åˆå¹¶éªŒè¯è¾¹\n",
    "                val_all_edges = torch.cat([val_edges, val_neg_edges], dim=1)\n",
    "                val_labels = torch.cat([\n",
    "                    torch.ones(num_val_edges, device=device),\n",
    "                    torch.zeros(num_val_edges, device=device)\n",
    "                ])\n",
    "                \n",
    "                # é¢„æµ‹\n",
    "                val_predictions = model(x, edge_index, val_all_edges)\n",
    "                \n",
    "                # è®¡ç®—æŒ‡æ ‡\n",
    "                val_auc = roc_auc_score(val_labels.cpu(), val_predictions.cpu())\n",
    "                val_ap = average_precision_score(val_labels.cpu(), val_predictions.cpu())\n",
    "                \n",
    "                history['train_loss'].append(loss.item())\n",
    "                history['val_auc'].append(val_auc)\n",
    "                history['val_ap'].append(val_ap)\n",
    "                \n",
    "                print(f\"Epoch {epoch+1:03d}: Loss={loss.item():.4f}, \"\n",
    "                      f\"Val AUC={val_auc:.4f}, Val AP={val_ap:.4f}\")\n",
    "    \n",
    "    print(\"\\nè®­ç»ƒå®Œæˆ!\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆï¼Œå‡å°‘epochsä»¥ä¾¿å¿«é€Ÿæ¼”ç¤ºï¼‰\n",
    "model, history = train_link_prediction_model(data, epochs=30, lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize-training"
   },
   "source": [
    "## 8. å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹\n",
    "\n",
    "ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±å’ŒæŒ‡æ ‡å˜åŒ–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": [],
   "metadata": {
    "id": "plot-training"
   },
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹\n",
    "def plot_training_history(history):\n",
    "    \"\"\"ç»˜åˆ¶è®­ç»ƒå†å²\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # è®­ç»ƒæŸå¤±\n",
    "    axes[0].plot(history['train_loss'], 'b-', linewidth=2)\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Training Loss')\n",
    "    axes[0].set_title('Training Loss Curve')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # éªŒè¯AUC\n",
    "    axes[1].plot(history['val_auc'], 'r-', linewidth=2)\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Validation AUC')\n",
    "    axes[1].set_title('Validation AUC Curve')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_ylim([0.5, 1.0])\n",
    "    \n",
    "    # éªŒè¯AP\n",
    "    axes[2].plot(history['val_ap'], 'g-', linewidth=2)\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Validation AP')\n",
    "    axes[2].set_title('Validation AP Curve')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].set_ylim([0.5, 1.0])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # è¾“å‡ºæœ€ä½³æŒ‡æ ‡\n",
    "    best_auc_idx = np.argmax(history['val_auc'])\n",
    "    best_ap_idx = np.argmax(history['val_ap'])\n",
    "    \n",
    "    print(f\"æœ€ä½³éªŒè¯AUC: {history['val_auc'][best_auc_idx]:.4f} (Epoch {(best_auc_idx+1)*10})\")\n",
    "    print(f\"æœ€ä½³éªŒè¯AP: {history['val_ap'][best_ap_idx]:.4f} (Epoch {(best_ap_idx+1)*10})\")\n",
    "\n",
    "# ç»˜åˆ¶è®­ç»ƒå†å²\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-evaluation"
   },
   "source": [
    "## 9. æ¨¡å‹è¯„ä¼°\n",
    "\n",
    "åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": [],
   "metadata": {
    "id": "evaluate-model"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, data):\n",
    "    \"\"\"åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x = data.x.to(device)\n",
    "        edge_index = data.edge_index.to(device)\n",
    "        \n",
    "        # æµ‹è¯•è¾¹\n",
    "        test_edges = data.edge_index[:, data.test_mask].to(device)\n",
    "        num_test_edges = test_edges.shape[1]\n",
    "        num_nodes = data.num_nodes\n",
    "        \n",
    "        # ç”Ÿæˆæµ‹è¯•è´Ÿæ ·æœ¬\n",
    "        test_neg_edges = torch.randint(0, num_nodes, (2, num_test_edges)).to(device)\n",
    "        \n",
    "        # åˆå¹¶æµ‹è¯•è¾¹\n",
    "        test_all_edges = torch.cat([test_edges, test_neg_edges], dim=1)\n",
    "        test_labels = torch.cat([\n",
    "            torch.ones(num_test_edges, device=device),\n",
    "            torch.zeros(num_test_edges, device=device)\n",
    "        ])\n",
    "        \n",
    "        # é¢„æµ‹\n",
    "        test_predictions = model(x, edge_index, test_all_edges)\n",
    "        \n",
    "        # è®¡ç®—å„ç§æŒ‡æ ‡\n",
    "        test_auc = roc_auc_score(test_labels.cpu(), test_predictions.cpu())\n",
    "        test_ap = average_precision_score(test_labels.cpu(), test_predictions.cpu())\n",
    "        \n",
    "        # è®¡ç®—F1åˆ†æ•°å’Œå‡†ç¡®ç‡\n",
    "        # ä½¿ç”¨0.5ä½œä¸ºé˜ˆå€¼å°†æ¦‚ç‡è½¬æ¢ä¸ºäºŒå…ƒé¢„æµ‹\n",
    "        binary_predictions = (test_predictions > 0.5).float()\n",
    "        test_f1 = f1_score(test_labels.cpu(), binary_predictions.cpu())\n",
    "        test_accuracy = accuracy_score(test_labels.cpu(), binary_predictions.cpu())\n",
    "        \n",
    "        # è®¡ç®—PR-AUC\n",
    "        from sklearn.metrics import precision_recall_curve, auc\n",
    "        precision, recall, _ = precision_recall_curve(test_labels.cpu(), test_predictions.cpu())\n",
    "        test_pr_auc = auc(recall, precision)\n",
    "        \n",
    "        # è¾“å‡ºç»“æœ\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"æµ‹è¯•é›†æ€§èƒ½è¯„ä¼°\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"AUC (ROCæ›²çº¿ä¸‹é¢ç§¯): {test_auc:.4f}\")\n",
    "        print(f\"AP (å¹³å‡ç²¾åº¦): {test_ap:.4f}\")\n",
    "        print(f\"PR-AUC (ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿ä¸‹é¢ç§¯): {test_pr_auc:.4f}\")\n",
    "        print(f\"F1åˆ†æ•°: {test_f1:.4f}\")\n",
    "        print(f\"å‡†ç¡®ç‡: {test_accuracy:.4f}\")\n",
    "        \n",
    "        # ç»˜åˆ¶ROCæ›²çº¿\n",
    "        from sklearn.metrics import roc_curve\n",
    "        fpr, tpr, _ = roc_curve(test_labels.cpu(), test_predictions.cpu())\n",
    "        \n",
    "        plt.figure(figsize=(10, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC = {test_auc:.3f}')\n",
    "        plt.plot([0, 1], [0, 1], 'r--', linewidth=1, alpha=0.5)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # ç»˜åˆ¶PRæ›²çº¿\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(recall, precision, 'g-', linewidth=2, label=f'AP = {test_ap:.3f}')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.legend(loc='lower left')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return {\n",
    "            'test_auc': test_auc,\n",
    "            'test_ap': test_ap,\n",
    "            'test_pr_auc': test_pr_auc,\n",
    "            'test_f1': test_f1,\n",
    "            'test_accuracy': test_accuracy\n",
    "        }\n",
    "\n",
    "# è¯„ä¼°æ¨¡å‹\n",
    "results = evaluate_model(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prediction-demo"
   },
   "source": [
    "## 10. é“¾è·¯é¢„æµ‹æ¼”ç¤º\n",
    "\n",
    "ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé“¾è·¯é¢„æµ‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": NULL,
   "metadata": {
    "id": "predict-example"
   },
   "outputs": [],
   "source": [
    "def predict_links(model, data, node_pairs):\n",
    "    \"\"\"é¢„æµ‹ç»™å®šèŠ‚ç‚¹å¯¹ä¹‹é—´æ˜¯å¦å­˜åœ¨é“¾æ¥\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x = data.x.to(device)\n",
    "        edge_index = data.edge_index.to(device)\n",
    "        \n",
    "        # å°†èŠ‚ç‚¹å¯¹è½¬æ¢ä¸ºå¼ é‡\n",
    "        edge_label_index = torch.tensor(node_pairs, device=device).T\n",
    "        \n",
    "        # é¢„æµ‹\n",
    "        predictions = model(x, edge_index, edge_label_index)\n",
    "        \n",
    "        # å°†ç»“æœè½¬æ¢ä¸ºPythonåˆ—è¡¨\n",
    "        predictions = predictions.cpu().numpy()\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# ç¤ºä¾‹ï¼šé¢„æµ‹ä¸€äº›èŠ‚ç‚¹å¯¹ä¹‹é—´æ˜¯å¦å­˜åœ¨é“¾æ¥\n",
    "print(\"\\né“¾è·¯é¢„æµ‹ç¤ºä¾‹:\")\n",
    "print(\"é¢„æµ‹ä»¥ä¸‹èŠ‚ç‚¹å¯¹ä¹‹é—´å­˜åœ¨é“¾æ¥çš„æ¦‚ç‡:\")\n",
    "\n",
    "# åˆ›å»ºä¸€äº›ç¤ºä¾‹èŠ‚ç‚¹å¯¹\n",
    "example_pairs = [\n",
    "    [0, 1],   # å‡è®¾çš„è¾¹\n",
    "    [2, 3],   # å‡è®¾çš„è¾¹\n",
    "    [4, 5],   # å‡è®¾çš„è¾¹\n",
    "    [0, 10],  # å¯èƒ½ä¸å­˜åœ¨çš„è¾¹\n",
    "    [1, 15]   # å¯èƒ½ä¸å­˜åœ¨çš„è¾¹\n",
    "]\n",
    "\n",
    "# è¿›è¡Œé¢„æµ‹\n",
    "predictions = predict_links(model, data, example_pairs)\n",
    "\n",
    "# æ˜¾ç¤ºç»“æœ\n",
    "for i, (src, dst) in enumerate(example_pairs):\n",
    "    prob = predictions[i]\n",
    "    print(f\"  èŠ‚ç‚¹ {src} â†’ èŠ‚ç‚¹ {dst}: é“¾æ¥æ¦‚ç‡ = {prob:.4f}\", end=\"\")\n",
    "    \n",
    "    # ç®€å•è§£é‡Š\n",
    "    if prob > 0.7:\n",
    "        print(\" (é«˜æ¦‚ç‡å­˜åœ¨é“¾æ¥)\")\n",
    "    elif prob > 0.3:\n",
    "        print(\" (ä¸­ç­‰æ¦‚ç‡å­˜åœ¨é“¾æ¥)\")\n",
    "    else:\n",
    "        print(\" (ä½æ¦‚ç‡å­˜åœ¨é“¾æ¥)\")\n",
    "\n",
    "print(\"\\næç¤º: æ¦‚ç‡>0.5é€šå¸¸è¡¨ç¤ºé¢„æµ‹å­˜åœ¨é“¾æ¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## 11. ç»“è®ºä¸ä¸‹ä¸€æ­¥\n",
    "\n",
    "æ­å–œï¼æ‚¨å·²ç»æˆåŠŸè¿è¡Œäº†WikiLinks GNNé“¾è·¯é¢„æµ‹æ¼”ç¤ºã€‚\n",
    "\n",
    "### ğŸ¯ å…³é”®æ”¶è·\n",
    "\n",
    "1. **ç†è§£äº†å›¾ç¥ç»ç½‘ç»œçš„åŸºæœ¬åŸç†** - é€šè¿‡GCNç­‰æ¨¡å‹å­¦ä¹ å›¾ç»“æ„æ•°æ®\n",
    "2. **æŒæ¡äº†é“¾è·¯é¢„æµ‹ä»»åŠ¡** - é¢„æµ‹å›¾ä¸­èŠ‚ç‚¹ä¹‹é—´æ½œåœ¨çš„é“¾æ¥å…³ç³»\n",
    "3. **å®è·µäº†å®Œæ•´çš„æœºå™¨å­¦ä¹ æµç¨‹** - ä»æ•°æ®åŠ è½½ã€æ¨¡å‹è®­ç»ƒåˆ°ç»“æœè¯„ä¼°\n",
    "\n",
    "### ğŸ”§ è¿›ä¸€æ­¥æ¢ç´¢\n",
    "\n",
    "1. **å®éªŒä¸åŒæ¨¡å‹æ¶æ„** - å°è¯•GATã€GraphSAGEç­‰å…¶ä»–GNNæ¨¡å‹\n",
    "2. **è°ƒæ•´è¶…å‚æ•°** - å­¦ä¹ ç‡ã€éšè—å±‚ç»´åº¦ã€dropoutç‡ç­‰\n",
    "3. **ä½¿ç”¨çœŸå®æ•°æ®** - åœ¨å®Œæ•´çš„WikiLinksæ•°æ®é›†ä¸Šè®­ç»ƒ\n",
    "4. **æ¢ç´¢åº”ç”¨åœºæ™¯** - çŸ¥è¯†å›¾è°±è¡¥å…¨ã€ç¤¾äº¤ç½‘ç»œæ¨èç­‰\n",
    "\n",
    "### ğŸ“š èµ„æºé“¾æ¥\n",
    "\n",
    "- [GitHubä»“åº“](https://github.com/inneedloveBu/wikinet-link-prediction)\n",
    "- [é¡¹ç›®æ–‡æ¡£](https://github.com/inneedloveBu/wikinet-link-prediction/wiki)\n",
    "- [è®ºæ–‡ä¸å‚è€ƒæ–‡çŒ®](https://github.com/inneedloveBu/wikinet-link-prediction#references)\n",
    "\n",
    "### ğŸš€ åœ¨æ‚¨è‡ªå·±çš„é¡¹ç›®ä¸­ä½¿ç”¨\n",
    "\n",
    "```python\n",
    "# åœ¨æ‚¨çš„ä»£ç ä¸­ä½¿ç”¨WikiLinksæ¨¡å‹\n",
    "# 1. å…‹éš†ä»“åº“\n",
    "# 2. å¯¼å…¥æ¨¡å‹\n",
    "# 3. åŠ è½½é¢„è®­ç»ƒæƒé‡æˆ–è®­ç»ƒæ–°æ¨¡å‹\n",
    "# 4. å¯¹æ‚¨çš„å›¾æ•°æ®è¿›è¡Œé¢„æµ‹\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": NULL,
   "metadata": {
    "id": "save-model"
   },
   "outputs": [],
   "source": [
    "# ä¿å­˜æ¨¡å‹ï¼ˆå¯é€‰ï¼‰\n",
    "print(\"\\nä¿å­˜æ¨¡å‹...\")\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'history': history,\n",
    "    'results': results\n",
    "}, 'wikilinks_demo_model.pth')\n",
    "\n",
    "print(\"æ¨¡å‹å·²ä¿å­˜ä¸º 'wikilinks_demo_model.pth'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final-note"
   },
   "source": [
    "---\n",
    "\n",
    "**æ„Ÿè°¢ä½¿ç”¨WikiLinks GNNé“¾è·¯é¢„æµ‹æ¼”ç¤ºï¼**\n",
    "\n",
    "å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·åœ¨GitHubä»“åº“ä¸­æäº¤Issueã€‚\n",
    "\n",
    "ç¥æ‚¨åœ¨å›¾ç¥ç»ç½‘ç»œçš„å­¦ä¹ å’Œç ”ç©¶ä¸­å–å¾—æˆåŠŸï¼âœ¨"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
